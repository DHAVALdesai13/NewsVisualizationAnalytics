{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tqdm\n",
    "import csv\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.287055969238281\n"
     ]
    }
   ],
   "source": [
    "csv.field_size_limit(100000000)\n",
    "csvpath = \"data/all_sampled2.csv\"\n",
    "num_articles = 1e10\n",
    "\n",
    "news = []\n",
    "\n",
    "with open(csvpath) as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    t0 = time.time()\n",
    "    for i, row in enumerate(csv_reader):\n",
    "        # if i%1000==0:\n",
    "        #   print(i)\n",
    "        if i>=num_articles:\n",
    "            break\n",
    "        article = \",\".join(row[7:-3])\n",
    "        date = row[2].strip().split(' ')[0].replace('-', '')[1:7]+\"01\"\n",
    "        source = row[-1].split(\"'\")[1]\n",
    "        link = row[-3]\n",
    "        \n",
    "        news_source_dict = {}\n",
    "        news_source_dict['date'] = date\n",
    "        news_source_dict['news_source'] = source\n",
    "        news_source_dict['url'] = link\n",
    "        news_source_dict['article'] = article\n",
    "        \n",
    "        news.append(news_source_dict)\n",
    "    \n",
    "\n",
    "\n",
    "    t1 = time.time() - t0\n",
    "    print(t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76061\n",
      "21913\n",
      "14364\n",
      "2996\n",
      "16165\n",
      "2050\n",
      "10348\n",
      "18714\n",
      "4961\n",
      "9558\n",
      "8547\n",
      "4034\n",
      "3044\n",
      "1334\n",
      "2869\n",
      "4991\n",
      "4456\n",
      "5225\n",
      "4626\n",
      "2046\n",
      "9072\n",
      "438\n",
      "1614\n",
      "1207\n",
      "951\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "preds = open(\"data/preds.txt\").read().split('\\n')[:-1]\n",
    "preds_ = list(map(lambda x: x.split(' ')[1], preds))\n",
    "# print(preds_)\n",
    "\n",
    "for i, elem in enumerate(news):\n",
    "    if i>=len(preds_):\n",
    "        break\n",
    "    elem['pred_label'] = preds_[i]\n",
    "\n",
    "news = news[:len(preds_)]\n",
    "\n",
    "news_dict = {}\n",
    "for elem in news:\n",
    "#     key = elem['news_source']\n",
    "    key = elem['news_source']\n",
    "    if key in news_dict:\n",
    "        news_dict[key].append(elem)\n",
    "    else:\n",
    "        news_dict[key] = [elem]\n",
    "        \n",
    "for key in news_dict:\n",
    "    print(len(news_dict[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Reuters 76061\n",
      "The New York Times 21913\n",
      "People 14364\n",
      "CNBC 16165\n",
      "Vice 10348\n",
      "The Hill 18714\n",
      "CNN 9558\n",
      "Mashable 9072\n",
      "176195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'date': '20170801',\n",
       " 'news_source': 'Reuters',\n",
       " 'url': \" 'https://www.reuters.com/article/brief-ve-wong-to-pay-2016-dividend-on-oc/brief-ve-wong-to-pay-2016-dividend-on-oct-5-idUSL4N1KX33L'\",\n",
       " 'article': \" 'BRIEF-VE WONG to pay 2016 dividend on Oct. 5', 'Aug 11 (Reuters) - VE WONG CORP : * Says it will pay cash dividend of T$1 per share for 2016 to shareholders on Oct. 5 Source text in Chinese: goo.gl/438Y2D Further company coverage: (Beijing Headline News)'\",\n",
       " 'pred_label': 'TECH'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count=0\n",
    "news_dict2 = {}\n",
    "for key in news_dict:\n",
    "    num = len(news_dict[key])\n",
    "    count+=num\n",
    "    if num>=9000:\n",
    "        news_dict2[key] = news_dict[key]\n",
    "\n",
    "\n",
    "print(len(news_dict2))\n",
    "\n",
    "count=0\n",
    "for key in news_dict2:\n",
    "    count+=len(news_dict2[key])\n",
    "    num = len(news_dict2[key])\n",
    "    print(key, num)\n",
    "\n",
    "print(count)\n",
    "\n",
    "news_dict2[\"Reuters\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reuters\n",
      "2 76061\n",
      "The New York Times\n",
      "2 21913\n",
      "People\n",
      "2 14364\n",
      "CNBC\n",
      "2 16165\n",
      "Vice\n",
      "2 10348\n",
      "The Hill\n",
      "2 18714\n",
      "CNN\n",
      "2 9558\n",
      "Mashable\n",
      "2 9072\n"
     ]
    }
   ],
   "source": [
    "news_dict3 = {}\n",
    "# for key in news_dict2:\n",
    "#     news_dict3[key] = {}\n",
    "    \n",
    "for key in news_dict2:\n",
    "#     years = [elem['date'][:4] for elem in news_dict2[key]]\n",
    "    row = {}\n",
    "    for elem in news_dict2[key]:\n",
    "        year = elem['date'][:1]\n",
    "#         year = elem['date']\n",
    "\n",
    "        if year in row:\n",
    "            row[year].append(elem)\n",
    "        else:\n",
    "            row[year] = [elem]\n",
    "        \n",
    "    news_dict3[key] = row\n",
    "#     print(len(row['2019']))\n",
    "\n",
    "\n",
    "count = 0\n",
    "for key in news_dict3:\n",
    "    print(key)\n",
    "    for key2 in news_dict3[key]:\n",
    "        print(key2, len(news_dict3[key][key2]))\n",
    "\n",
    "# print(news_dict3['Reuters']['2016'][100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_dict4 = {}\n",
    "for key in news_dict3:\n",
    "    news_dict4[key] = {}\n",
    "    for key2 in news_dict3[key]:\n",
    "        row = {}\n",
    "        for elem in news_dict3[key][key2]:\n",
    "            label = elem[\"pred_label\"]\n",
    "            if label in row:\n",
    "                row[label].append(elem)\n",
    "            else:\n",
    "                row[label] = [elem]\n",
    "        news_dict4[key][key2] = row\n",
    "\n",
    "category_list = []\n",
    "count = 0\n",
    "for key in news_dict4:\n",
    "    for key2 in news_dict4[key]:\n",
    "        for key3 in news_dict4[key][key2]:\n",
    "            elem = news_dict4[key][key2]\n",
    "            num = len(news_dict4[key][key2][key3])\n",
    "#             print(key3, num)\n",
    "            category_list.append(key3)\n",
    "            count+=num\n",
    "        \n",
    "#         break\n",
    "#     break\n",
    "category_list = sorted(list(set(category_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df = []\n",
    "# for key in news_dict4:\n",
    "#     for key2 in news_dict4[key]:\n",
    "#         res = []\n",
    "#         for key3 in category_list:\n",
    "#             if key3 in news_dict4[key][key2]:\n",
    "#                 num = len(news_dict4[key][key2][key3])\n",
    "#                 num = str(num)\n",
    "#             else:\n",
    "#                 num = ''\n",
    "#             res.append(num)\n",
    "\n",
    "#         df.append([key]+[key2]+res)\n",
    "# #             write_res = csv_template.format(key, key2, *res)\n",
    "# #             outfile.write(write_res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = []\n",
    "for key in news_dict4:\n",
    "    tot = len(news_dict[key])\n",
    "    for key2 in news_dict4[key]:\n",
    "        res = []\n",
    "        for key3 in category_list:\n",
    "            if key3 in news_dict4[key][key2]:\n",
    "                num = len(news_dict4[key][key2][key3])\n",
    "                frac = 100.*num/tot\n",
    "                num = str(num)\n",
    "            else:\n",
    "                num = ''\n",
    "                frac = 0\n",
    "            res.append(str(frac))\n",
    "\n",
    "        df.append([key]+[key2]+res)\n",
    "#             write_res = csv_template.format(key, key2, *res)\n",
    "#             outfile.write(write_res)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOSEN_CATS = [\"CRIME\", \"ENTERTAINMENT\", \"POLITICS\", \"SPORTS\", \"TECH\"]\n",
    "# df = []\n",
    "# for key in news_dict4:\n",
    "#     for key2 in news_dict4[key]:\n",
    "#         res = []\n",
    "#         tot = 0\n",
    "#         for key3 in category_list:\n",
    "#             if key3 in news_dict4[key][key2]:\n",
    "#                 num = len(news_dict4[key][key2][key3])\n",
    "#                 if key3 in CHOSEN_CATS:\n",
    "#                     tot+=num\n",
    "#         for key3 in category_list:\n",
    "#             if key3 in news_dict4[key][key2]:\n",
    "#                 num = len(news_dict4[key][key2][key3])\n",
    "#                 frac = 1.*num/tot\n",
    "#                 num = str(num)\n",
    "#             else:\n",
    "#                 frac = 0\n",
    "#                 num = ''\n",
    "#             res.append(str(frac))\n",
    "        \n",
    "\n",
    "#         df.append([key]+[key2]+res)\n",
    "# #             write_res = csv_template.format(key, key2, *res)\n",
    "# #             outfile.write(write_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_sort = df.copy()\n",
    "df_sort.sort(key = lambda x: x[1])\n",
    "df_sort = [[\"Publisher\", \"date\"]+ category_list] + df_sort\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# df_T = pd.DataFrame(df_sort).T.values.tolist()\n",
    "# df_T.pop(1)\n",
    "\n",
    "csv_template = \"\"\n",
    "for _ in range(len(category_list)):\n",
    "    csv_template+='{},'\n",
    "csv_template+='{}\\n'\n",
    "\n",
    "with open(\"data/barreal2.csv\", 'w') as outfile:\n",
    "    for row in df_sort:\n",
    "        row.pop(1)\n",
    "        outrow = csv_template.format(*row)\n",
    "        outfile.write(outrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11, 22, 44]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [11,22,33,44]\n",
    "a.pop(2)\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
